{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from fpdf import FPDF\n",
    "\n",
    "\n",
    "\n",
    "def get_hotel_data(hotel_name):\n",
    "    # Base search URL\n",
    "    url = f'https://www.dineout.co.in/surat-restaurants?search_str={hotel_name}'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Fetch the search page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Get the first hotel object\n",
    "    first_object = soup.find_all('div', class_='restnt-card-wrap-new')\n",
    "    if not first_object:\n",
    "        print(\"No hotels found!\")\n",
    "        return None\n",
    "\n",
    "    first_object = first_object[0]\n",
    "\n",
    "    # Extract the \"data-link\" value\n",
    "    data_link = first_object.find('div', class_='img cursor').get('data-link')\n",
    "    if not data_link:\n",
    "        print(\"No data-link found in the first object!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Construct full hotel URL\n",
    "    hotel_url = \"https://www.dineout.co.in\" + data_link\n",
    "\n",
    "    # -------------------------------- Selenium for Dynamic Content --------------------------------\n",
    "    # Initialize Selenium WebDriver\n",
    "    service = Service(r'D:\\Company\\chromedriver.exe')  # Update the path if needed\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    try:\n",
    "        # Open the hotel page\n",
    "        driver.get(hotel_url)\n",
    "\n",
    "        # Wait for the menu gallery to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"demo-gallery\"))\n",
    "        )\n",
    "\n",
    "        # Extract page source after rendering\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Extract the <ul> element containing the menu\n",
    "        menu_gallery = soup.find('ul', class_='d-flex demo-gallery')\n",
    "        menu_links = []\n",
    "        if menu_gallery:\n",
    "            for link in menu_gallery.find_all('a'):\n",
    "                href = link.get('href')\n",
    "                if href:\n",
    "                    menu_links.append(href)\n",
    "\n",
    "        # Extract \"restnt-info\" details\n",
    "        details_section = soup.find('div', class_='restnt-details_info')\n",
    "        restaurant_details = {}\n",
    "        \n",
    "    \n",
    "        name = details_section.find('h1').text.strip()\n",
    "        #location = details_section.find('div', class_='Address')\n",
    "        cost_for_two = details_section.find('div', class_='restnt-cost').text.split('|')[0].strip()\n",
    "         \n",
    "        type_header = soup.find('h4', string=\"TYPE\")  \n",
    "        if type_header:\n",
    "            type = type_header.find_next_sibling('p').text.strip()  \n",
    "        \n",
    "        type_header_2 = soup.find('h5', string=\"Call the restaurant\")  \n",
    "        if type_header_2:\n",
    "            moblie_number = type_header_2.find_next_sibling('p').text.strip() \n",
    "\n",
    "        type_header_3 = soup.find('h3', string=\"Address:\") \n",
    "        location = type_header_3.find_next_sibling('p').text.strip()\n",
    "                \n",
    "        # Look for the div containing the rating dynamically\n",
    "        rating_div = soup.find('div', class_=lambda c: c and 'rest-rating' in c)\n",
    "        \n",
    "        rating = rating_div.text.strip()\n",
    "                  \n",
    "\n",
    "        restaurant_details = {\n",
    "            \"name\": name,\n",
    "            \"location\": location,\n",
    "            \"cost_for_two\": cost_for_two,  \n",
    "            \"rating\": rating,\n",
    "            \"type\": type,\n",
    "            \"moblie_number\": moblie_number \n",
    "        }\n",
    "\n",
    "        restaurant_details[\"type\"] = \"Dineout Pay\" in restaurant_details[\"type\"]\n",
    "\n",
    "        cost_for_two = cost_for_two.split(' ')[1].strip()  # Extract the numeric part\n",
    "        restaurant_details[\"cost_for_two\"] = cost_for_two\n",
    "        \n",
    "        file_menu_name = name + \"'s menu.pdf\"\n",
    "        create_pdf_from_images(menu_links, file_menu_name)\n",
    "\n",
    "        return restaurant_details\n",
    "\n",
    " \n",
    "\n",
    "    finally:\n",
    "        # Quit Selenium WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def create_pdf_from_images(image_urls, output_file):\n",
    "    # Initialize FPDF\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "    for i, url in enumerate(image_urls, start=1):\n",
    "        try:\n",
    "            # Fetch the image\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "            # Open the image using Pillow\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            img_path = f\"temp_image_{i}.jpg\"  # Temporary file to save the image\n",
    "\n",
    "            # Save the image locally\n",
    "            img.save(img_path, \"JPEG\")\n",
    "\n",
    "            # Add the image to the PDF\n",
    "            pdf.add_page()\n",
    "            pdf.image(img_path, x=10, y=10, w=190)  # Adjust dimensions as needed\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process image {url}: {e}\")\n",
    "\n",
    "    # Save the PDF to the specified output file\n",
    "    pdf.output(output_file)\n",
    "    print(f\"PDF saved as {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved as Zhingalala's menu.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Zhingalala',\n",
       " 'location': 'Luxuria Trade Hub, 7, Dumas Road Piplod Near Rundhnath Mahadev Mandir  South Surat 395007',\n",
       " 'cost_for_two': '1,000',\n",
       " 'rating': '4.3',\n",
       " 'type': True,\n",
       " 'moblie_number': '0261-2971918'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_name = input(\"Enter the hotel name: \") # Ex. Zhingalala\n",
    "get_hotel_data(hotel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
